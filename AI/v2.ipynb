{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsJdp772DKKq"
   },
   "source": [
    "# Import Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "PHXDsf62CjCx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "y5JjpgRLDP4y",
    "outputId": "89ca2f5b-c007-4532-a549-358536c54864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.11.0'"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FZntxWoaDhMF",
    "outputId": "7efbb5c5-c320-42eb-cbbc-d1d75dcf6bb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.11.0'"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q54GH9XulvWu",
    "outputId": "dcfc0d39-1256-490a-cdbb-72e6eabeead6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ep1KBSt1Dmci"
   },
   "source": [
    "# Read in the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "BUnaJHajDkrm"
   },
   "outputs": [],
   "source": [
    "rawData = pd.read_excel(\"Full-Data-Set-UnderOver-2020-21.xlsx\")\n",
    "rawData = rawData.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "ks3rdgFaEFev",
    "outputId": "3ac46a3b-8a13-48cd-c507-9223d705fa8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Unnamed: 0            GP             W             L         W_PCT  \\\ncount  16358.000000  16358.000000  16358.000000  16358.000000  16358.000000   \nmean    8178.500000     42.738538     22.225883     20.512654      0.513536   \nstd     4722.292187     24.007672     15.430625     13.403097      0.183969   \nmin        0.000000      1.000000      0.000000      0.000000      0.000000   \n25%     4089.250000     22.000000     10.000000      9.000000      0.382000   \n50%     8178.500000     43.000000     19.000000     19.000000      0.520000   \n75%    12267.750000     64.000000     32.000000     29.000000      0.645000   \nmax    16357.000000     82.000000     72.000000     69.000000      1.000000   \n\n                MIN           FGM           FGA        FG_PCT          FG3M  \\\ncount  16358.000000  16358.000000  16358.000000  16358.000000  16358.000000   \nmean      48.353754     37.952763     83.493654      0.454603      8.192689   \nstd        0.325391      2.318313      3.831431      0.019487      2.528331   \nmin       48.000000     28.000000     67.300000      0.339000      0.700000   \n25%       48.100000     36.400000     80.900000      0.442000      6.300000   \n50%       48.300000     37.800000     83.400000      0.454000      7.900000   \n75%       48.500000     39.300000     86.100000      0.467000      9.900000   \nmax       55.500000     50.000000    100.000000      0.571000     20.000000   \n\n       ...    BLK_RANK.1   BLKA_RANK.1     PF_RANK.1    PFD_RANK.1  \\\ncount  ...  16358.000000  16358.000000  16358.000000  16358.000000   \nmean   ...     15.307984     15.168480     15.353344     15.477809   \nstd    ...      8.621444      8.633495      8.640666      8.612438   \nmin    ...      1.000000      1.000000      1.000000      1.000000   \n25%    ...      8.000000      8.000000      8.000000      8.000000   \n50%    ...     15.000000     15.000000     15.000000     16.000000   \n75%    ...     23.000000     23.000000     23.000000     23.000000   \nmax    ...     30.000000     30.000000     30.000000     30.000000   \n\n         PTS_RANK.1  PLUS_MINUS_RANK.1         Score  Home-Team-Win  \\\ncount  16358.000000       16358.000000  16358.000000   16358.000000   \nmean      15.275095          15.036007    204.782186       0.591148   \nstd        8.633568           8.664541     22.006642       0.491637   \nmin        1.000000           1.000000     22.000000       0.000000   \n25%        8.000000           7.000000    190.000000       0.000000   \n50%       15.000000          15.000000    204.000000       1.000000   \n75%       23.000000          22.000000    219.000000       1.000000   \nmax       30.000000          30.000000    329.000000       1.000000   \n\n                 OU      OU-Cover  \ncount  16358.000000  16358.000000  \nmean     204.598392      0.515344  \nstd       21.729718      0.526352  \nmin        1.000000      0.000000  \n25%      194.500000      0.000000  \n50%      203.500000      1.000000  \n75%      214.000000      1.000000  \nmax     1955.500000      2.000000  \n\n[8 rows x 109 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>GP</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W_PCT</th>\n      <th>MIN</th>\n      <th>FGM</th>\n      <th>FGA</th>\n      <th>FG_PCT</th>\n      <th>FG3M</th>\n      <th>...</th>\n      <th>BLK_RANK.1</th>\n      <th>BLKA_RANK.1</th>\n      <th>PF_RANK.1</th>\n      <th>PFD_RANK.1</th>\n      <th>PTS_RANK.1</th>\n      <th>PLUS_MINUS_RANK.1</th>\n      <th>Score</th>\n      <th>Home-Team-Win</th>\n      <th>OU</th>\n      <th>OU-Cover</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>...</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n      <td>16358.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8178.500000</td>\n      <td>42.738538</td>\n      <td>22.225883</td>\n      <td>20.512654</td>\n      <td>0.513536</td>\n      <td>48.353754</td>\n      <td>37.952763</td>\n      <td>83.493654</td>\n      <td>0.454603</td>\n      <td>8.192689</td>\n      <td>...</td>\n      <td>15.307984</td>\n      <td>15.168480</td>\n      <td>15.353344</td>\n      <td>15.477809</td>\n      <td>15.275095</td>\n      <td>15.036007</td>\n      <td>204.782186</td>\n      <td>0.591148</td>\n      <td>204.598392</td>\n      <td>0.515344</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4722.292187</td>\n      <td>24.007672</td>\n      <td>15.430625</td>\n      <td>13.403097</td>\n      <td>0.183969</td>\n      <td>0.325391</td>\n      <td>2.318313</td>\n      <td>3.831431</td>\n      <td>0.019487</td>\n      <td>2.528331</td>\n      <td>...</td>\n      <td>8.621444</td>\n      <td>8.633495</td>\n      <td>8.640666</td>\n      <td>8.612438</td>\n      <td>8.633568</td>\n      <td>8.664541</td>\n      <td>22.006642</td>\n      <td>0.491637</td>\n      <td>21.729718</td>\n      <td>0.526352</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>48.000000</td>\n      <td>28.000000</td>\n      <td>67.300000</td>\n      <td>0.339000</td>\n      <td>0.700000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4089.250000</td>\n      <td>22.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>0.382000</td>\n      <td>48.100000</td>\n      <td>36.400000</td>\n      <td>80.900000</td>\n      <td>0.442000</td>\n      <td>6.300000</td>\n      <td>...</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>7.000000</td>\n      <td>190.000000</td>\n      <td>0.000000</td>\n      <td>194.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8178.500000</td>\n      <td>43.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>0.520000</td>\n      <td>48.300000</td>\n      <td>37.800000</td>\n      <td>83.400000</td>\n      <td>0.454000</td>\n      <td>7.900000</td>\n      <td>...</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>16.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>204.000000</td>\n      <td>1.000000</td>\n      <td>203.500000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>12267.750000</td>\n      <td>64.000000</td>\n      <td>32.000000</td>\n      <td>29.000000</td>\n      <td>0.645000</td>\n      <td>48.500000</td>\n      <td>39.300000</td>\n      <td>86.100000</td>\n      <td>0.467000</td>\n      <td>9.900000</td>\n      <td>...</td>\n      <td>23.000000</td>\n      <td>23.000000</td>\n      <td>23.000000</td>\n      <td>23.000000</td>\n      <td>23.000000</td>\n      <td>22.000000</td>\n      <td>219.000000</td>\n      <td>1.000000</td>\n      <td>214.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16357.000000</td>\n      <td>82.000000</td>\n      <td>72.000000</td>\n      <td>69.000000</td>\n      <td>1.000000</td>\n      <td>55.500000</td>\n      <td>50.000000</td>\n      <td>100.000000</td>\n      <td>0.571000</td>\n      <td>20.000000</td>\n      <td>...</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>329.000000</td>\n      <td>1.000000</td>\n      <td>1955.500000</td>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 109 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MefJrXUvHHJy"
   },
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "DQZUrgHUHA3b"
   },
   "outputs": [],
   "source": [
    "filteredData = rawData.drop([\"Unnamed: 0\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"Score\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"GP\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"GP.1\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"Home-Team-Win\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"TEAM_NAME\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"Date\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"MIN\", \"W\", \"W.1\", \"L\", \"L.1\", \"PLUS_MINUS\", \"PLUS_MINUS.1\", \"PLUS_MINUS_RANK\", \"PLUS_MINUS_RANK.1\", \"W_RANK\", \"W_RANK.1\", \"L_RANK\", \"L_RANK.1\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"MIN.1\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"MIN_RANK.1\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"MIN_RANK\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"TEAM_NAME.1\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"Date.1\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"OU\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"OU-Cover\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"GP_RANK\"], axis = 1)\n",
    "filteredData = filteredData.drop([\"GP_RANK.1\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAOvw2kOusdd"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWhlML-GeLgN"
   },
   "source": [
    "#### Get the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "NJZxoaf_ucLR"
   },
   "outputs": [],
   "source": [
    "output = rawData['Home-Team-Win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXBxjFR8g7V-",
    "outputId": "30d595b4-534c-466c-a80b-37fce964be85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16358\n"
     ]
    }
   ],
   "source": [
    "#get 80% for training 20% for testing\n",
    "print(len(filteredData))\n",
    "test_len = int(len(filteredData) * 0.8)\n",
    "x_train = filteredData.take(range(test_len))\n",
    "x_test = filteredData.take(range(test_len, len(filteredData)))\n",
    "y_train = output.take(range(test_len))\n",
    "y_test = output.take(range(test_len, len(filteredData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "lQgt1Rr2iWqZ"
   },
   "outputs": [],
   "source": [
    "test_len = int(len(filteredData) * 0.9)\n",
    "x_train = filteredData.take(range(test_len))\n",
    "x_test = filteredData.take(range(test_len, len(filteredData)))\n",
    "y_train = output.take(range(test_len))\n",
    "y_test = output.take(range(test_len, len(filteredData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "rxSIiK8Dea0T"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(170, activation=tf.nn.relu6))\n",
    "model.add(tf.keras.layers.Dropout(rate=.25))\n",
    "model.add(tf.keras.layers.Dense(150, activation=tf.nn.relu6))\n",
    "model.add(tf.keras.layers.Dense(75, activation=tf.nn.relu6))\n",
    "model.add(tf.keras.layers.Dropout(rate=.15))\n",
    "model.add(tf.keras.layers.Dense(30, activation=tf.nn.relu6))\n",
    "model.add(tf.keras.layers.Dense(15, activation=tf.nn.relu6))\n",
    "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax, name=\"output_layer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G98ljKwHf43I",
    "outputId": "82b68fc3-4c44-4848-b3b2-f7099a5b57fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (14722, 84)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (14722, 170)              14450     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (14722, 170)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (14722, 150)              25650     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (14722, 75)               11325     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (14722, 75)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (14722, 30)               2280      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (14722, 15)               465       \n",
      "                                                                 \n",
      " output_layer (Dense)        (14722, 2)                32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,202\n",
      "Trainable params: 54,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build( x_train.shape )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "kQWah4KxgXiD"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.compile(Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "HVaJA-BYgb8r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4/4 - 0s - loss: 0.5840 - accuracy: 0.6941 - val_loss: 0.5733 - val_accuracy: 0.7046 - 138ms/epoch - 35ms/step\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damon/Desktop/Model/lib/python3.10/site-packages/keras/engine/data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.5822 - accuracy: 0.6978 - val_loss: 0.5748 - val_accuracy: 0.7021 - 93ms/epoch - 23ms/step\n",
      "Epoch 3/60\n",
      "4/4 - 0s - loss: 0.5838 - accuracy: 0.6954 - val_loss: 0.5742 - val_accuracy: 0.7021 - 91ms/epoch - 23ms/step\n",
      "Epoch 4/60\n",
      "4/4 - 0s - loss: 0.5836 - accuracy: 0.6969 - val_loss: 0.5703 - val_accuracy: 0.7048 - 86ms/epoch - 22ms/step\n",
      "Epoch 5/60\n",
      "4/4 - 0s - loss: 0.5798 - accuracy: 0.7016 - val_loss: 0.5775 - val_accuracy: 0.6984 - 96ms/epoch - 24ms/step\n",
      "Epoch 6/60\n",
      "4/4 - 0s - loss: 0.5808 - accuracy: 0.7003 - val_loss: 0.5712 - val_accuracy: 0.7055 - 97ms/epoch - 24ms/step\n",
      "Epoch 7/60\n",
      "4/4 - 0s - loss: 0.5814 - accuracy: 0.6973 - val_loss: 0.5705 - val_accuracy: 0.7068 - 93ms/epoch - 23ms/step\n",
      "Epoch 8/60\n",
      "4/4 - 0s - loss: 0.5767 - accuracy: 0.7009 - val_loss: 0.5735 - val_accuracy: 0.7043 - 83ms/epoch - 21ms/step\n",
      "Epoch 9/60\n",
      "4/4 - 0s - loss: 0.5841 - accuracy: 0.6899 - val_loss: 0.5705 - val_accuracy: 0.7073 - 83ms/epoch - 21ms/step\n",
      "Epoch 10/60\n",
      "4/4 - 0s - loss: 0.5801 - accuracy: 0.7002 - val_loss: 0.5740 - val_accuracy: 0.7043 - 77ms/epoch - 19ms/step\n",
      "Epoch 11/60\n",
      "4/4 - 0s - loss: 0.5816 - accuracy: 0.7010 - val_loss: 0.5707 - val_accuracy: 0.7075 - 78ms/epoch - 19ms/step\n",
      "Epoch 12/60\n",
      "4/4 - 0s - loss: 0.5773 - accuracy: 0.7049 - val_loss: 0.5705 - val_accuracy: 0.7075 - 79ms/epoch - 20ms/step\n",
      "Epoch 13/60\n",
      "4/4 - 0s - loss: 0.5786 - accuracy: 0.7005 - val_loss: 0.5721 - val_accuracy: 0.7032 - 81ms/epoch - 20ms/step\n",
      "Epoch 14/60\n",
      "4/4 - 0s - loss: 0.5755 - accuracy: 0.7033 - val_loss: 0.5710 - val_accuracy: 0.7052 - 80ms/epoch - 20ms/step\n",
      "Epoch 15/60\n",
      "4/4 - 0s - loss: 0.5776 - accuracy: 0.7024 - val_loss: 0.5689 - val_accuracy: 0.7057 - 79ms/epoch - 20ms/step\n",
      "Epoch 16/60\n",
      "4/4 - 0s - loss: 0.5755 - accuracy: 0.7022 - val_loss: 0.5717 - val_accuracy: 0.7050 - 76ms/epoch - 19ms/step\n",
      "Epoch 17/60\n",
      "4/4 - 0s - loss: 0.5768 - accuracy: 0.7035 - val_loss: 0.5692 - val_accuracy: 0.7050 - 81ms/epoch - 20ms/step\n",
      "Epoch 18/60\n",
      "4/4 - 0s - loss: 0.5746 - accuracy: 0.7007 - val_loss: 0.5715 - val_accuracy: 0.7039 - 79ms/epoch - 20ms/step\n",
      "Epoch 19/60\n",
      "4/4 - 0s - loss: 0.5763 - accuracy: 0.7004 - val_loss: 0.5702 - val_accuracy: 0.7079 - 74ms/epoch - 18ms/step\n",
      "Epoch 20/60\n",
      "4/4 - 0s - loss: 0.5748 - accuracy: 0.6992 - val_loss: 0.5731 - val_accuracy: 0.7034 - 77ms/epoch - 19ms/step\n",
      "Epoch 21/60\n",
      "4/4 - 0s - loss: 0.5738 - accuracy: 0.7087 - val_loss: 0.5721 - val_accuracy: 0.7066 - 74ms/epoch - 19ms/step\n",
      "Epoch 22/60\n",
      "4/4 - 0s - loss: 0.5747 - accuracy: 0.7050 - val_loss: 0.5701 - val_accuracy: 0.7089 - 77ms/epoch - 19ms/step\n",
      "Epoch 23/60\n",
      "4/4 - 0s - loss: 0.5727 - accuracy: 0.7085 - val_loss: 0.5715 - val_accuracy: 0.7055 - 80ms/epoch - 20ms/step\n",
      "Epoch 24/60\n",
      "4/4 - 0s - loss: 0.5713 - accuracy: 0.7102 - val_loss: 0.5686 - val_accuracy: 0.7089 - 80ms/epoch - 20ms/step\n",
      "Epoch 25/60\n",
      "4/4 - 0s - loss: 0.5753 - accuracy: 0.7093 - val_loss: 0.5675 - val_accuracy: 0.7070 - 78ms/epoch - 20ms/step\n",
      "Epoch 26/60\n",
      "4/4 - 0s - loss: 0.5735 - accuracy: 0.7042 - val_loss: 0.5713 - val_accuracy: 0.7036 - 81ms/epoch - 20ms/step\n",
      "Epoch 27/60\n",
      "4/4 - 0s - loss: 0.5733 - accuracy: 0.7023 - val_loss: 0.5675 - val_accuracy: 0.7077 - 78ms/epoch - 20ms/step\n",
      "Epoch 28/60\n",
      "4/4 - 0s - loss: 0.5720 - accuracy: 0.7115 - val_loss: 0.5681 - val_accuracy: 0.7064 - 80ms/epoch - 20ms/step\n",
      "Epoch 29/60\n",
      "4/4 - 0s - loss: 0.5695 - accuracy: 0.7115 - val_loss: 0.5668 - val_accuracy: 0.7122 - 78ms/epoch - 20ms/step\n",
      "Epoch 30/60\n",
      "4/4 - 0s - loss: 0.5738 - accuracy: 0.7039 - val_loss: 0.5696 - val_accuracy: 0.7039 - 78ms/epoch - 19ms/step\n",
      "Epoch 31/60\n",
      "4/4 - 0s - loss: 0.5692 - accuracy: 0.7094 - val_loss: 0.5675 - val_accuracy: 0.7098 - 82ms/epoch - 20ms/step\n",
      "Epoch 32/60\n",
      "4/4 - 0s - loss: 0.5727 - accuracy: 0.7091 - val_loss: 0.5712 - val_accuracy: 0.7046 - 85ms/epoch - 21ms/step\n",
      "Epoch 33/60\n",
      "4/4 - 0s - loss: 0.5706 - accuracy: 0.7071 - val_loss: 0.5679 - val_accuracy: 0.7073 - 78ms/epoch - 19ms/step\n",
      "Epoch 34/60\n",
      "4/4 - 0s - loss: 0.5695 - accuracy: 0.7102 - val_loss: 0.5669 - val_accuracy: 0.7084 - 88ms/epoch - 22ms/step\n",
      "Epoch 35/60\n",
      "4/4 - 0s - loss: 0.5702 - accuracy: 0.7084 - val_loss: 0.5707 - val_accuracy: 0.7057 - 80ms/epoch - 20ms/step\n",
      "Epoch 36/60\n",
      "4/4 - 0s - loss: 0.5697 - accuracy: 0.7080 - val_loss: 0.5663 - val_accuracy: 0.7077 - 85ms/epoch - 21ms/step\n",
      "Epoch 37/60\n",
      "4/4 - 0s - loss: 0.5668 - accuracy: 0.7128 - val_loss: 0.5673 - val_accuracy: 0.7066 - 85ms/epoch - 21ms/step\n",
      "Epoch 38/60\n",
      "4/4 - 0s - loss: 0.5702 - accuracy: 0.7056 - val_loss: 0.5697 - val_accuracy: 0.7036 - 85ms/epoch - 21ms/step\n",
      "Epoch 39/60\n",
      "4/4 - 0s - loss: 0.5712 - accuracy: 0.7076 - val_loss: 0.5656 - val_accuracy: 0.7102 - 79ms/epoch - 20ms/step\n",
      "Epoch 40/60\n",
      "4/4 - 0s - loss: 0.5672 - accuracy: 0.7164 - val_loss: 0.5688 - val_accuracy: 0.7057 - 78ms/epoch - 20ms/step\n",
      "Epoch 41/60\n",
      "4/4 - 0s - loss: 0.5671 - accuracy: 0.7119 - val_loss: 0.5654 - val_accuracy: 0.7113 - 80ms/epoch - 20ms/step\n",
      "Epoch 42/60\n",
      "4/4 - 0s - loss: 0.5653 - accuracy: 0.7114 - val_loss: 0.5672 - val_accuracy: 0.7066 - 77ms/epoch - 19ms/step\n",
      "Epoch 43/60\n",
      "4/4 - 0s - loss: 0.5666 - accuracy: 0.7092 - val_loss: 0.5664 - val_accuracy: 0.7077 - 85ms/epoch - 21ms/step\n",
      "Epoch 44/60\n",
      "4/4 - 0s - loss: 0.5666 - accuracy: 0.7084 - val_loss: 0.5656 - val_accuracy: 0.7064 - 81ms/epoch - 20ms/step\n",
      "Epoch 45/60\n",
      "4/4 - 0s - loss: 0.5643 - accuracy: 0.7124 - val_loss: 0.5691 - val_accuracy: 0.7030 - 83ms/epoch - 21ms/step\n",
      "Epoch 46/60\n",
      "4/4 - 0s - loss: 0.5663 - accuracy: 0.7101 - val_loss: 0.5641 - val_accuracy: 0.7098 - 84ms/epoch - 21ms/step\n",
      "Epoch 47/60\n",
      "4/4 - 0s - loss: 0.5660 - accuracy: 0.7104 - val_loss: 0.5671 - val_accuracy: 0.7070 - 79ms/epoch - 20ms/step\n",
      "Epoch 48/60\n",
      "4/4 - 0s - loss: 0.5650 - accuracy: 0.7152 - val_loss: 0.5634 - val_accuracy: 0.7093 - 79ms/epoch - 20ms/step\n",
      "Epoch 49/60\n",
      "4/4 - 0s - loss: 0.5668 - accuracy: 0.7101 - val_loss: 0.5656 - val_accuracy: 0.7086 - 78ms/epoch - 19ms/step\n",
      "Epoch 50/60\n",
      "4/4 - 0s - loss: 0.5624 - accuracy: 0.7124 - val_loss: 0.5648 - val_accuracy: 0.7127 - 79ms/epoch - 20ms/step\n",
      "Epoch 51/60\n",
      "4/4 - 0s - loss: 0.5636 - accuracy: 0.7189 - val_loss: 0.5670 - val_accuracy: 0.7107 - 79ms/epoch - 20ms/step\n",
      "Epoch 52/60\n",
      "4/4 - 0s - loss: 0.5674 - accuracy: 0.7100 - val_loss: 0.5663 - val_accuracy: 0.7084 - 77ms/epoch - 19ms/step\n",
      "Epoch 53/60\n",
      "4/4 - 0s - loss: 0.5644 - accuracy: 0.7119 - val_loss: 0.5639 - val_accuracy: 0.7118 - 80ms/epoch - 20ms/step\n",
      "Epoch 54/60\n",
      "4/4 - 0s - loss: 0.5623 - accuracy: 0.7126 - val_loss: 0.5648 - val_accuracy: 0.7122 - 77ms/epoch - 19ms/step\n",
      "Epoch 55/60\n",
      "4/4 - 0s - loss: 0.5636 - accuracy: 0.7116 - val_loss: 0.5642 - val_accuracy: 0.7125 - 78ms/epoch - 19ms/step\n",
      "Epoch 56/60\n",
      "4/4 - 0s - loss: 0.5626 - accuracy: 0.7164 - val_loss: 0.5642 - val_accuracy: 0.7120 - 81ms/epoch - 20ms/step\n",
      "Epoch 57/60\n",
      "4/4 - 0s - loss: 0.5627 - accuracy: 0.7156 - val_loss: 0.5637 - val_accuracy: 0.7136 - 80ms/epoch - 20ms/step\n",
      "Epoch 58/60\n",
      "4/4 - 0s - loss: 0.5602 - accuracy: 0.7195 - val_loss: 0.5650 - val_accuracy: 0.7122 - 78ms/epoch - 19ms/step\n",
      "Epoch 59/60\n",
      "4/4 - 0s - loss: 0.5644 - accuracy: 0.7148 - val_loss: 0.5651 - val_accuracy: 0.7116 - 77ms/epoch - 19ms/step\n",
      "Epoch 60/60\n",
      "4/4 - 0s - loss: 0.5626 - accuracy: 0.7143 - val_loss: 0.5641 - val_accuracy: 0.7122 - 79ms/epoch - 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f694c4722f0>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=60, validation_split=0.30, batch_size=3_000, verbose=2, shuffle=True, workers=15, use_multiprocessing=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPaTuHBtuByU",
    "outputId": "0520a618-fc33-40a2-b80a-94ace163c9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 84) dtype=float64>,). Consider rewriting this model with the Functional API.\n",
      "52/52 [==============================] - 0s 715us/step\n"
     ]
    }
   ],
   "source": [
    "todayPredictions = model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636\n",
      "1636\n",
      "0.0550122249388753\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(y_test))\n",
    "print(len(x_test))\n",
    "win = 0\n",
    "for i in range (0,len(todayPredictions)):\n",
    "    try:\n",
    "        if np.argmax(todayPredictions[i]) == y_test[i]:\n",
    "            win += 1\n",
    "    except Exception as e:\n",
    "        exit(1)\n",
    "\n",
    "print(win / len(todayPredictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVmwr3oOu4Fo"
   },
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_2022-12-14 01:16:26.534008/assets\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "model.save(f\"model_{datetime.datetime.utcnow()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bb68d0ea94455c6db74225640d58336d2197de5871f4cce798098ff3da94acb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
